---
title: "cindex"
format: html
editor: visual
---

The `echo: false` option disables the printing of code (only output is displayed).

```{r}
library(data.table)
library(mlr3)
library(mlr3learners)
library(mlr3measures)
library(ggplot2)
library(pec)
library(survival)
library(dplyr)
library(randomForestSRC)
library(survAUC) # concordance index
library(stringr)
library(mice)
library(ranger)
library(gbm)
```

## Reading Merged_V4 (from end of 7/7) and running the data imputation. This does NOT impute survival times, but it DOES impute age.at.admit and gcs_total.

```{r}
sps <- fread("../data/merged_v4.csv")

sps <- sps %>% select(-1)
sps <- sps %>% mutate(across(where(is.character), factor))
met <- make.method(sps)
met["age.at.admit"] <- "pmm"
met["gcs_total"]    <- "pmm"
multicat <- c("admission_type", "admission_location", "discharge_location",
              "insurance", "language", "religion",
              "marital_status", "ethnicity")
# use random forest for imputation
met[multicat] <- "cart"
# not imputed data
met[c("subject_id", "survival_days", "event")] <- ""
# ───────────────────────────────────────────────────────────
# 3. predictorMatrix：
# ───────────────────────────────────────────────────────────
pred <- make.predictorMatrix(sps)
pred[ , c("subject_id", "survival_days", "event",
          grep("^PO_", names(sps), value = TRUE))] <- 0   # excluded from predictors
# ───────────────────────────────────────────────────────────
# 4. mice
# ───────────────────────────────────────────────────────────
set.seed(2025)
imp <- mice(sps,
            m                  = 5,
            method             = met,
            predictorMatrix    = pred,
            maxit              = 20,
            printFlag          = TRUE)
```

### Storing the imputation results in sps_imputed.csv

```{r}
write.csv(imp$data, "sps_imputed.csv", row.names = FALSE)
```

## START FROM HERE TO NOT DO IMPUTATION

## Imports imputed dataset and removes pseudoobservation entries (they are not interpretable but are developed based on the outcome, so it's unfair to train off of them).

```{r}

# MERGED V4 = PRE IMPUTATION
sps <- fread("../data/sps_imputed.csv")

# removing predictor matrices? (ask about this)
sps <- sps %>% select(-starts_with("PO_"))

# Drop unwanted columns
#drop_cols <- c(
#  # we want to drop these
#  "dbsource", "formulary_drug_cd_list", "admission_location", "admittime", #"dischtime",
#  "edregtime", "edouttime", "diagnosis", "latest_gcs_time", "comorbidities", "proc#.icd9_list",
#  
#  # dropping but not sure how to handle yet
#  "gcs_total", "gcs_verbal", "gcs_motor", "gcs_eye", "language", "drug#.Miscellaneous", "diag.Missing"
#)

# dropping those columns
#sps[, (drop_cols) := NULL]

# drop patients with missing age (until we figure out what imputation we're doing)
#sps <- sps[!is.na(age.at.admit)]



```

## Grouping Ethnicity (Eliana's Code)

```{r}
# ELIANA'S SPS MERGE CODE
sps <- sps %>% mutate(ethnicity = case_when(
    str_detect(ethnicity, regex("ASIAN", ignore_case = TRUE)) ~ "Asian",
    str_detect(ethnicity, regex("WHITE|MIDDLE", ignore_case = TRUE)) ~ "White",
    str_detect(ethnicity, regex("BLACK", ignore_case = TRUE)) ~ "Black or African American",
    str_detect(ethnicity, regex("OTHER|PATIENT|UNABLE|UNKNOWN", ignore_case = TRUE)) ~ "Unknown",
    str_detect(ethnicity, regex("AMERICAN", ignore_case = TRUE)) ~ "American Indian or Alaska Native",
    str_detect(ethnicity, regex("HISPANIC", ignore_case = TRUE)) ~ "Hispanic",
    str_detect(ethnicity, regex("MULTI", ignore_case = TRUE)) ~ "More than one race",
    TRUE ~ ethnicity
  ))
```

## One Hot Encoding for Categorical Variables

```{r}
# categorical variables
cat_vars <- c("gender", "admission_type", "insurance", "religion", "marital_status", "ethnicity", "discharge_location", "intervention.group", "language")


# one-hot encode the categorical variables
mm <- model.matrix(~ . - 1, data = sps[, ..cat_vars])

# combining back with the rest of dataset
sps <- cbind(sps[, !cat_vars, with = FALSE], as.data.table(mm))

time_buckets <- c(7, 30, 60, 180, 365, 730)
```

## ignorable: some extra filtering that is no longer necessary

```{r}
# filter out zero survival
#sps <- sps[survival_days >= 0]

# Binary target
#sps[, survived_90 := survival_days >= 90]

# Fill NAs
#cols_to_fill <- setdiff(names(sps), c("age.at.admit", "gcs_total"))
#sps[, (cols_to_fill) := lapply(.SD, function(x) ifelse(is.na(x), 0, x)), .SDcols = #cols_to_fill]

# Remove ID columns
#X <- sps[, !c("subject_id", "survival_days", "survived_90", "event"), with = FALSE]
#y <- sps[, .(time = survival_days, status = as.integer(event))]

# Combine for mlr3 task
#data <- cbind(X, y)
```

## splitting into train/test

```{r}

#sps <- sps[, !duplicated(names(sps)), with = FALSE]

# Prepare survival object
#sps <- sps %>% dplyr::filter(!is.na(event), !is.na(survival_days))

# Train/test split
set.seed(7)
train_idx <- sample(seq_len(nrow(sps)), size = 0.6 * nrow(sps))
train_data <- sps[train_idx, ]
test_data <- sps[-train_idx, ]

train_data_clean <- train_data %>%
  select(-subject_id) %>%
  mutate(across(where(is.character), as.factor))

test_data_clean <- test_data %>%
  select(-subject_id) %>%
  mutate(across(where(is.character), as.factor))

train_data_clean <- train_data_clean %>% filter(complete.cases(.))
test_data_clean <- test_data_clean %>% filter(complete.cases(.))

# fit random survival forest
rsf_model <- rfsrc(Surv(survival_days, event) ~ ., data = train_data_clean, importance="permute")

rsf_pred <- predict(rsf_model, newdata = test_data_clean)

# fit gradient boosting model (Cox PH boosting)
```

```{r}

vi <- rsf_model$importance

# Convert to data frame and sort
vi_df <- data.frame(
  variable = names(vi),
  importance = as.numeric(vi)
) %>%
  dplyr::arrange(desc(importance)) %>%
  dplyr::slice(1:10)  # Top 10


max_len <- 15

vi_df <- vi_df %>%
  mutate(
    variable_abbr = ifelse(
      str_length(variable) > max_len,
      str_trunc(variable, max_len, ellipsis = "..."),
      variable
    )
  )

ggplot(vi_df, aes(x = reorder(variable_abbr, -importance), y = importance)) +
  geom_col(fill = "steelblue") +
  labs(
    title = "Top 10 Feature Importances (RSF)",
    x = "Variable",
    y = "Permutation Importance"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

## Setting up RSF

```{r}
# fit random survival forest
rsf_model <- rfsrc(Surv(survival_days, event) ~ ., data = train_data_clean)

rsf_pred <- predict(rsf_model, newdata = test_data_clean)
```

## faulty C-Index of RSF

```{r}
y_test <- Surv(test_data_clean$survival_days, test_data_clean$event)

# risk score supposedly can be approximated as 1 - predicted survival probability at a fixed time (e.g., median), or use predicted mortality (1 - survival) at last time point

# risk score: 1 - survival probability at max time point predicted
risk_scores <- 1 - rsf_pred$survival[, ncol(rsf_pred$survival)]

rsf_pred <- predict(rsf_model, newdata = test_data_clean)

rsf_cindex <- randomForestSRC::get.cindex(time = test_data_clean$survival_days,
                               censoring = test_data_clean$event,
                               predicted = -rsf_pred$predicted)
print(paste("RSF C-index:", round(rsf_cindex, 3)))
```

## real C-index of RSF

```{r}

time_idx <- sapply(time_buckets, function(t) which.min(abs(rsf_pred$time.interest - t)))

# Get predicted survival probabilities at each bucket
# Risk scores = 1 - survival probability
surv_probs <- rsf_pred$survival[, time_idx]
risk_scores <- 1 - surv_probs

cindex_results <- data.frame(Time = time_buckets, C_index = NA)

for (i in seq_along(time_buckets)) {
  t <- time_buckets[i]
  risk <- risk_scores[, i]

  # Compute time-dependent ROC and AUC
  roc <- timeROC(
    T = test_data_clean$survival_days,
    delta = test_data_clean$event,
    marker = risk,
    cause = 1,
    times = t,
    iid = TRUE
  )
  
  cindex_results$C_index[i] <- roc$AUC[2]
}

print(paste(cindex_results, mean(cindex_results$C_index)))
mean(cindex_results$C_index)
```

```{r}
ggplot(cindex_results, aes(x = factor(Time), y = C_index)) +
  geom_col(fill = "#2E86C1", width = 0.6) +
  geom_text(aes(label = round(C_index, 3)), vjust = -0.5, size = 5) +
  labs(
    title = "C-index by Survival Time Probability Prediction",
    x = "Survival Time (Days)",
    y = "C-index"
  ) +
  ylim(0, 1) +
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    axis.title = element_text(face = "bold"),
    axis.text = element_text(size = 12)
  )

```

## IBS Score for RSF

```{r}
library(randomForestSRC)
library(pec)

# Fit RSF model

# Define evaluation times (use training event times)
times <- rsf_pred$time.interest

#fmla <- as.formula(paste("Surv(survival_days, event) ~", paste(predictors, collapse = "+")))

ibs_rsf_result <- pec(
  object = list("RSF" = rsf_model),
  formula = Surv(survival_days, event) ~ 1,
  data = test_data_clean,
  times = times,
  cens.model = "cox",      # Use Kaplan-Meier to estimate censoring survival function
  exact = FALSE,
  splitMethod = "none"    # No cross-validation
)

crps(ibs_rsf_result)
```

```{r}
# Get predicted survival probabilities from RSF
rsf_pred <- predict(rsf_model, newdata = test_data_clean, importance = FALSE)

# Extract survival probabilities at observed time points
rsf_surv_probs <- rsf_pred$survival  # Matrix: rows = test samples, cols = time points
times <- rsf_pred$time.interest      # Time points at which survival is estimated

# Compute Brier score & IBS
brier_rsf <- riskRegression::Score(
  list("RSF" = rsf_surv_probs),
  formula = Surv(survival_days, event) ~ 1,
  data = test_data_clean,
  times = times,
  summary = "ibs",
  cens.model = "km"  # Method for handling censoring
)

# The IBS is already calculated by riskRegression::Score - no need for manual integration
# Just extract it directly from the results
ibs_rsf <- brier_rsf$Brier$score[brier_rsf$Brier$score$model == "RSF", "IBS"]

times <- brier_scores$times
brier_values <- brier_scores$Brier

# Compute IBS using trapezoidal integration
ibs_manual <- sum(
  diff(times) * (brier_values[-1] + brier_values[-length(brier_values)]) / 2
) / max(times)

# Compare with built-in IBS (should be very close)
print(paste("RSF IBS:", ibs_manual))
```

```{r}
plot.variable(rsf_model,
              xvar.names = c("age.at.admit"),      # Feature of interest
              partial = TRUE,          # Turn on partial dependence
              surv.type = "surv",      # Can also try "hazard" or "mort"
              time = 365,               # Time at which to evaluate survival probability
              main = c("Age Partial Dependence Plot (365 Days)"),
              xlab = "Age at Hospital Admission",
  ylab = "Survival Probability at 365 Days",)
```

## Setting up GBM

```{r}
gbm_model <- gbm(Surv(survival_days, event) ~ ., 
                 data = train_data_clean,
                 distribution = "coxph",
                 n.trees = 100)

gbm_pred <- predict(gbm_model, newdata = test_data_clean, n.trees = 100)
```

## BAD C-Index of GBM

```{r}
gbm_concordance <- concordance(y_test ~ gbm_pred)
if (gbm_concordance$concordance < 0.5) {
  gbm_concordance$concordance <- 1 - gbm_concordance$concordance
}

print(paste("GBM C-index:", round(gbm_concordance$concordance, 3)))

## ADDITIONAL CODE THAT GETS THE SAME THING ###
## '''
## {r}
## gbm_cindex <- Hmisc::rcorr.cens(
##   x = -gbm_pred,  # Note the negative sign to ensure proper risk direction
##   S = y_test
## )["C Index"]
## print(paste("GBM C-index (Hmisc):", round(gbm_cindex, 3)))
## '''
```

## GBM Predicted Survival Times

```{r}
# 1. Fit GBM Cox model
gbm_model <- gbm(Surv(survival_days, event) ~ ., 
                 data = train_data_clean,
                 distribution = "coxph",
                 n.trees = 100)


# 2. Predict log-relative hazard (linear predictor)
gbm_pred <- predict(gbm_model, newdata = test_data_clean, n.trees = 100)

# 3. Fit baseline survival from training data (Kaplan-Meier)
base_surv <- survfit(Surv(survival_days, event) ~ 1, data = train_data_clean)

# 4. Define desired time buckets
time_buckets <- c(7, 30, 60, 180, 365, 730)

# 5. Compute predicted survival for each person at each bucket
# Create a matrix to store survival probabilities
surv_probs <- matrix(NA, nrow = length(gbm_pred), ncol = length(time_buckets))
colnames(surv_probs) <- paste0("t_", time_buckets)

# Normalize the linear predictors
gbm_pred_centered <- gbm_pred - mean(gbm_pred)

for (j in seq_along(time_buckets)) {
  t <- time_buckets[j]
  # Find closest time in baseline survival
  closest_time_idx <- which.min(abs(base_surv$time - t))
  S0_t <- base_surv$surv[closest_time_idx]

  # Individual survival prediction: S(t)^exp(lp)
  surv_probs[, j] <- S0_t ^ exp(gbm_pred_centered)
}

test_data <- test_data %>% filter(complete.cases(.))

# Optional: bind with subject ID if available
gbm_surv_preds <- data.frame(subject_id = test_data$subject_id, surv_probs)
print(head(gbm_surv_preds, 10))  # Show predictions for first 10 patients
```

## IBS of GBM

```{r}

# 2. Define custom prediction function for pec
predictSurvProb.gbm <- function(object, newdata, times, ...) {
  # Linear predictor from gbm
  lp <- predict(object, newdata = newdata, n.trees = object$n.trees)
  
  # Baseline survival (from training data)
  base_surv <- survfit(Surv(survival_days, event) ~ 1, data = train_data_clean)
  
  # Interpolate baseline survival at requested times
  baseline_surv <- approx(
    x = base_surv$time,
    y = base_surv$surv,
    xout = times,
    method = "constant",
    rule = 2
  )$y

  # Return matrix of survival probabilities: S(t|x) = S0(t)^exp(lp - mean(lp))
  outer(lp - mean(lp), baseline_surv, function(lp, s0) s0 ^ exp(lp))
}

# 3. Define evaluation times
times <- rsf_pred$time.interest 

# 4. Run pec (with your custom GBM prediction)
ibs_result <- pec(
  object = list("GBM" = gbm_model),
  formula = Surv(survival_days, event) ~ 1,
  data = test_data_clean,
  times = times,
  cens.model = "none",
  exact = FALSE,
  splitMethod = "none"
)


#ibs_result <- c


ibs_result

# 5. Extract and print IBS
ibs_gbm <- crps(ibs_result)["GBM"]
crps(ibs_result)
```

## C-Index of GBM

```{r}
library(timeROC)

# Initialize list to store C-index results
cindex_results <- data.frame(Time = time_buckets, C_index = NA)

for (i in seq_along(time_buckets)) {
  t <- time_buckets[i]
  prob <- surv_probs[, i]  # Survival probability at time t
  risk_score <- -prob      # Higher risk = lower survival

  roc <- timeROC(
    T = test_data_clean$survival_days,
    delta = test_data_clean$event,
    marker = risk_score,
    cause = 1,
    times = t,
    iid = TRUE
  )
  
  cindex_results$C_index[i] <- roc$AUC[2]  # AUC at time t
}

print(cindex_results)
mean(cindex_results$C_index)
```

```{r}
ggplot(cindex_results, aes(x = factor(Time), y = C_index)) +
  geom_col(fill = "#2E86C1", width = 0.6) +
  geom_text(aes(label = round(C_index, 3)), vjust = -0.5, size = 5) +
  labs(
    title = "C-index by Survival Time Probability Prediction",
    x = "Survival Time (Days)",
    y = "C-index"
  ) +
  ylim(0, 1) +
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    axis.title = element_text(face = "bold"),
    axis.text = element_text(size = 12)
  )

```

## RSF Predicted Survival Times

```{r}

get_surv_probs <- function(surv_row, time_interest, time_buckets) {
  sapply(time_buckets, function(t) {
    idx <- max(which(time_interest <= t))
    surv_row[idx]
  })
}

# printing survival probabilities for first 5 test patients
for (i in 1:5) {
  surv_probs <- get_surv_probs(rsf_pred$survival[i, ], rsf_pred$time.interest, time_buckets)
  cat(sprintf("Patient %d survival probabilities:\n", i))
  for (j in seq_along(time_buckets)) {
    cat(sprintf("  P(survival > %d days) = %.3f\n", time_buckets[j], surv_probs[j]))
  }
}
```

```{r}
rcorr.cens # CORRELATION COEFFICIENT FOR CENSORED DATA
```

# permutation test

## ranger, run random forest, nperm = \> 100, Altmann version, try janitza if it doesn't run

## try getting graph with p values / z scores of each covariate

## Ranger Model Creation and Running It, w/ Feature Importance

```{r}

# Prepare the data (using your existing train/test split)
# Remove ID columns and the binary survival target (keep only survival_days and event)

# have to "clean" the names for ranger to work
clean_names <- function(df) {
  names(df) <- gsub("[^[:alnum:]]", "_", names(df))
  names(df) <- gsub("_+", "_", names(df))  # replace multiple _ with single
  names(df) <- gsub("_$", "", names(df))   # remove trailing _
  names(df) <- gsub("^_", "", names(df))   # remove leading _
  df
}

train_ranger <- train_data_clean %>% clean_names()
train_ranger <- train_ranger[complete.cases(train_ranger), ]

test_ranger <- test_data_clean %>% clean_names()

# Fit the ranger random survival forest
ranger_model <- ranger(
  formula = Surv(survival_days, event) ~ .,
  data = train_ranger,
  num.trees = 1000,               # Number of trees
  mtry = 8,                    # Number of variables to possibly split at (default is sqrt(p))
  min.node.size = 9,             # Minimal node size
  splitrule = "logrank",          # Splitting rule for survival
  importance = "permutation",     # Variable importance mode
  seed = 7,                       # For reproducibility
  verbose = TRUE                  # Print progress
)

# Print the model
print(ranger_model)

# Make predictions on test data
ranger_pred <- predict(
  object = ranger_model,
  data = test_ranger,
  type = "response"  # Returns predicted survival times
)

# You can also get survival probabilities at specific time points
# First get unique event times from training data
times <- sort(unique(train_ranger$survival_days[train_ranger$event == 1]))

# Get survival probabilities at these times
ranger_surv <- predict(
  object = ranger_model,
  data = test_ranger,
  type = "response",
  fun = function(x) x$survival  # Returns survival probabilities
)

# To get predicted survival probabilities at 90 days:
# Find the time point closest to 90 days
time_idx <- which.min(abs(times - 90))
surv_prob_90 <- ranger_surv$survival[, time_idx]

# Variable importance
if (!is.null(ranger_model$variable.importance)) {
  vi <- sort(ranger_model$variable.importance, decreasing = TRUE)
  print(vi)
  barplot(vi, las = 2, cex.names = 0.7, main = "Variable Importance")
}
```

```{r}
# Define time buckets
time_buckets <- c(7, 30, 60, 180, 365, 730)

# Step 1: Get survival probabilities at all bucket times
predictSurvProb.ranger <- function(object, newdata, times, ...) {
  pred <- predict(object, data = newdata)$survival
  train_times <- object$unique.death.times
  idx <- sapply(times, function(t) which.min(abs(train_times - t)))
  surv_probs <- pred[, idx, drop = FALSE]
  return(surv_probs)
}

# Predict survival probabilities at specified time buckets
bucket_surv_probs <- predictSurvProb.ranger(ranger_model, test_ranger, times = time_buckets)

# Step 2: For each bucket, compute binary survived/not and C-index (or AUC)
c_index_results <- data.frame(Time = time_buckets, C_index = NA)

for (i in seq_along(time_buckets)) {
  t <- time_buckets[i]
  
  # Define binary survival outcome at time t: 1 = survived beyond t, 0 = died before t
  test_ranger <- test_ranger %>%
    mutate(survived_t = ifelse(survival_days >= t & event == 0, 1, 0))
  
  # Predicted survival probabilities at time t
  surv_prob_t <- bucket_surv_probs[, i]
  
  # Risk = 1 - survival probability
  risk_score_t <- 1 - surv_prob_t
  
  # C-index for binary outcome at time t
  # Use concordance() from survival
  concord <- concordance(Surv(rep(1, nrow(test_ranger)), test_ranger$survived_t) ~ risk_score_t)
  c_index_results$C_index[i] <- concord$concordance
}

# Step 3: Print results
print(c_index_results)

# plot
ggplot(c_index_results, aes(x = factor(Time), y = C_index)) +
  geom_col(fill = "#2E86C1", width = 0.6) +
  geom_text(aes(label = round(C_index, 3)), vjust = -0.5, size = 5) +
  labs(
    title = "C-index by Survival Time Probability Prediction",
    x = "Survival Time (Days)",
    y = "C-index"
  ) +
  ylim(0, 1) +
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    axis.title = element_text(face = "bold"),
    axis.text = element_text(size = 12)
  )
```

```{r}
mean(c_index_results$C_index)
```

```{r}

```

## Ranger probability predictions for each interval

```{r}
predictSurvProb.ranger <- function(object, newdata, times, ...) {
  pred <- predict(object, data = newdata)$survival
  train_times <- object$unique.death.times
  idx <- sapply(times, function(t) which.min(abs(train_times - t)))
  surv_probs <- pred[, idx, drop = FALSE]
  return(surv_probs)
}

pred_surv <- predictSurvProb(ranger_model, newdata = test_ranger, times = times)
```

## C-Index for Ranger

```{r}

# Predict survival probabilities at a fixed time, say 90 days
time_idx <- which.min(abs(times - 90))
surv_probs_90 <- predictSurvProb.ranger(ranger_model, test_ranger, times = times)[, time_idx]

# Risk score as 1 - survival probability
risk_score <- surv_probs_90

# Concordance index
conc <- concordance(Surv(test_ranger$survival_days, test_ranger$event) ~ risk_score)
print(conc$concordance)

```

## IBS Score for Ranger

```{r}
# Define formula explicitly (no dot)
predictors <- setdiff(names(test_ranger), c("survival_days", "event"))
fmla <- as.formula(paste("Surv(survival_days, event) ~", paste(predictors, collapse = "+")))

# times: vector of evaluation times (e.g., unique event times)
times <- sort(unique(train_ranger$survival_days[train_ranger$event == 1]))

pec_results <- pec(
  object = list("RSF Ranger" = ranger_model),
  formula = fmla,
  data = test_ranger,
  times = times,
  cens.model = "cox",
  exact = FALSE,
  splitMethod = "none",
  predictSurvProb = predictSurvProb.ranger
)

# Extract Integrated Brier Score (IBS)
ibs <- crps(pec_results)  # crps() returns IBS integrated over times
print(ibs)
```

## Permutation Test

```{r}

names(train_data_clean) <- make.names(names(train_data_clean))
train_data_clean <- train_data_clean %>%
  filter(!is.na(survival_days))

#train_data_clean <- train_data_clean %>% select(-language)
train_data_clean <- train_data_clean[complete.cases(train_data_clean), ]


imp_pvals <- importance_pvalues(
  ranger_model,
  method = "altmann",   # Recommended for survival models
  formula = Surv(survival_days, event) ~ .,
  data = train_data_clean,
  num.permutations = 50
)

imp_pvals
```

+----------+--------------------+--------------+-----------+----------+
| \        | admission_location | age.at.admit | gcs_total |          |
| dbsource |                    |              |           |          |
|          | \<fctr\>           | \<dbl\>      | \<int\>   |          |
| \<fctr\> |                    |              |           |          |
+:=========+:===================+=============:+==========:+==========+
|          |                    |              |           |          |
+----------+--------------------+--------------+-----------+----------+

```{r}
imp_pvals_df <- as.data.frame(imp_pvals)
imp_pvals_df %>%
  arrange(desc(pvalue))
```

```{r}
library(tibble)
library(ggrepel)
imp_pvals_df <- imp_pvals_df %>%
  rownames_to_column("variable")

ggplot(imp_pvals_df, aes(x = importance, y = pvalue, color = pvalue < 0.05)) +
  geom_point() +
  geom_text_repel(
    aes(label = ifelse(pvalue < 0.05 | importance > 0.01, variable, "")),
    size = 3,
    max.overlaps = 100,  # Allow more overlaps before hiding labels
    force = 2,           # Increase repulsion force
    force_pull = 0.5,    # Reduce pull toward points
    min.segment.length = 0,  # Always draw segments
    box.padding = 0.5,   # More padding around labels
    point.padding = 0.2, # More padding around points
    nudge_x = 0,       # Slight nudge horizontally
    nudge_y = 0.1,       # Slight nudge vertically
    segment.color = "grey50",  # Make segments less prominent
    segment.alpha = 0.5,
    seed = 42            # For reproducibility
  ) +
  labs(title = "P-value vs. Importance (Significant Variables Labeled)") +
  theme_minimal()
```
